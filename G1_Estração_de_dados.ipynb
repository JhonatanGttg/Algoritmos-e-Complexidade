{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JhonatanGttg/Algoritmos-e-Complexidade/blob/main/G1_Estra%C3%A7%C3%A3o_de_dados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# G1 - Extração de Manchetes"
      ],
      "id": "intro"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install_title"
      },
      "source": [
        "## 1) Instalar dependências"
      ],
      "id": "install_title"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "install"
      },
      "execution_count": 1,
      "outputs": [],
      "source": [
        "%pip -q install requests beautifulsoup4 lxml urllib3"
      ],
      "id": "install"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imports_title"
      },
      "source": [
        "## 2) Importações e configurações"
      ],
      "id": "imports_title"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imports",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44327539-2500-45ce-f87c-61e230619a5d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurações definidas.\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import time\n",
        "from datetime import datetime, timezone\n",
        "from typing import List, Tuple, Set\n",
        "\n",
        "import requests\n",
        "from requests.adapters import HTTPAdapter\n",
        "from urllib3.util.retry import Retry\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin, urlparse\n",
        "\n",
        "# Configurações básicas\n",
        "G1_HOME = 'https://g1.globo.com/'\n",
        "DEFAULT_TIMEOUT = 20\n",
        "HEADERS = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0 Safari/537.36',\n",
        "    'Accept-Language': 'pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7',\n",
        "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
        "    'Referer': 'https://g1.globo.com/'\n",
        "}\n",
        "print('Configurações definidas.')"
      ],
      "id": "imports"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "session_title"
      },
      "source": [
        "## 3) Criar sessão HTTP com retries"
      ],
      "id": "session_title"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "session",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29feb429-d2e3-4253-9729-400b723d89a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sessão criada com retries.\n"
          ]
        }
      ],
      "source": [
        "def make_session() -> requests.Session:\n",
        "    s = requests.Session()\n",
        "    retry = Retry(total=5, backoff_factor=0.6, status_forcelist=[429, 500, 502, 503, 504], allowed_methods=frozenset(['GET','HEAD']))\n",
        "    adapter = HTTPAdapter(max_retries=retry)\n",
        "    s.mount('http://', adapter)\n",
        "    s.mount('https://', adapter)\n",
        "    s.headers.update(HEADERS)\n",
        "    return s\n",
        "\n",
        "SESSION = make_session()\n",
        "print('Sessão criada com retries.')"
      ],
      "id": "session"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "funcs_title"
      },
      "source": [
        "## 4) Funções utilitárias"
      ],
      "id": "funcs_title"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "funcs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86432074-5e48-4f30-dbca-cb98d0fb3f10"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Funções definidas.\n"
          ]
        }
      ],
      "source": [
        "def fetch_html(url: str) -> str:\n",
        "    last_err = None\n",
        "    for attempt in range(3):\n",
        "        try:\n",
        "            resp = SESSION.get(url, timeout=DEFAULT_TIMEOUT)\n",
        "            resp.raise_for_status()\n",
        "            return resp.text\n",
        "        except requests.RequestException as e:\n",
        "            last_err = e\n",
        "            time.sleep(1.0 + attempt * 0.7)\n",
        "    raise RuntimeError(f'Falha ao baixar URL {url}: {last_err}')\n",
        "\n",
        "def normalize_url(base: str, href: str) -> str:\n",
        "    if not href:\n",
        "        return ''\n",
        "    href = href.strip()\n",
        "    if href.startswith('#') or href.lower().startswith('javascript:'):\n",
        "        return ''\n",
        "    abs_url = urljoin(base, href)\n",
        "    parsed = urlparse(abs_url)\n",
        "    if parsed.scheme not in {'http', 'https'}:\n",
        "        return ''\n",
        "    return abs_url\n",
        "\n",
        "def parse_headlines(html: str, base_url: str) -> List[Tuple[str, str]]:\n",
        "    try:\n",
        "        soup = BeautifulSoup(html, 'lxml')\n",
        "    except Exception:\n",
        "        soup = BeautifulSoup(html, 'html.parser')\n",
        "    candidates: List[Tuple[str, str]] = []\n",
        "\n",
        "    def add_candidate(title: str, href: str):\n",
        "        title = (title or '').strip()\n",
        "        href = normalize_url(base_url, href)\n",
        "        if title and href:\n",
        "            candidates.append((title, href))\n",
        "\n",
        "    for a in soup.select('a.feed-post-link'):\n",
        "        title = a.get_text(strip=True)\n",
        "        href = a.get('href')\n",
        "        add_candidate(title, href)\n",
        "\n",
        "    for h in soup.select('h1 a, h2 a, h3 a'):\n",
        "        if 'feed-post-link' in (h.get('class') or []):\n",
        "            continue\n",
        "        title = h.get_text(strip=True)\n",
        "        href = h.get('href')\n",
        "        add_candidate(title, href)\n",
        "\n",
        "    for a in soup.select('div.feed-post-body-title a, div.bastian-feed-item a'):\n",
        "        title = a.get_text(strip=True)\n",
        "        href = a.get('href')\n",
        "        add_candidate(title, href)\n",
        "\n",
        "    seen_links: Set[str] = set()\n",
        "    seen_titles: Set[str] = set()\n",
        "    unique: List[Tuple[str, str]] = []\n",
        "    for title, link in candidates:\n",
        "        if link in seen_links:\n",
        "            continue\n",
        "        if title.lower() in seen_titles:\n",
        "            continue\n",
        "        seen_links.add(link)\n",
        "        seen_titles.add(title.lower())\n",
        "        unique.append((title, link))\n",
        "    return unique\n",
        "\n",
        "def save_to_csv(rows: List[Tuple[str, str]], out_path: str):\n",
        "    with open(out_path, 'w', newline='', encoding='utf-8') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['title', 'link', 'fetched_at'])\n",
        "        now = datetime.now(timezone.utc).isoformat()\n",
        "        for title, link in rows:\n",
        "            writer.writerow([title, link, now])\n",
        "print('Funções definidas.')"
      ],
      "id": "funcs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "run_title"
      },
      "source": [
        "## 5) Executar o scraper"
      ],
      "id": "run_title"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "run",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ee37885-0e10-45d6-fbdb-38d3ec89c072"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total coletado: 9\n",
            "Manchetes principais (título + link):\n",
            "01. Questionada sobre Bolsonaro, Casa Branca diz que Trump não teme usar 'meios militares'\n",
            "    https://g1.globo.com/mundo/noticia/2025/09/09/trump-nao-tem-medo-de-usar-meios-militares-para-proteger-liberdade-de-expressao-diz-casa-branca-sobre-eventual-condenacao-de-bolsonaro.ghtml\n",
            "02. Mega-Sena pode pagar R$ 46 milhões; veja números\n",
            "    https://g1.globo.com/loterias/mega-sena/noticia/2025/09/09/mega-sena-concurso-2912-resultado.ghtml\n",
            "03. Dino: 'Alguém acredita que o Mickey vai mudar julgamento?'\n",
            "    https://g1.globo.com/politica/noticia/2025/09/09/sera-que-alguem-acredita-que-um-tuite-de-presidente-estrangeiro-vai-mudar-o-julgamento-questiona-dino.ghtml\n",
            "04. Placar do julgamento: como votou cada ministro até agora\n",
            "    https://g1.globo.com/politica/noticia/2025/09/09/trama-golpista-placar-do-julgamento-infografico.ghtml\n",
            "05. VÍDEOS: reveja o momento em que Moraes vota pela condenação\n",
            "    https://g1.globo.com/politica/playlist/videos-terceiro-dia-de-julgamento-trama-golpista.ghtml\n",
            "06. Suspeito de incendiar banheiros químicos perto do STF é preso\n",
            "    https://g1.globo.com/df/distrito-federal/noticia/2025/09/09/pm-detem-suspeito-de-incendiar-banheiros-quimicos-na-esplanada-dos-ministerios-a-menos-de-2-km-do-stf.ghtml\n",
            "07. 'Ameaçam invadir o Brasil. Isso é inadmissível', diz Gleisi\n",
            "    https://g1.globo.com/politica/noticia/2025/09/09/gleisi-diz-que-e-inadmissivel-eua-falarem-em-usar-meios-militares-contra-brasil.ghtml\n",
            "08. Em recado ao Congresso, Dino diz que não cabe anistia\n",
            "    https://g1.globo.com/politica/noticia/2025/09/09/trama-golpista-dino-diz-que-nao-cabe-anistia-aos-crimes-julgados.ghtml\n",
            "09. Juiz não é 'samambaia jurídica': entenda falas de ministros\n",
            "    https://g1.globo.com/politica/noticia/2025/09/09/juiz-nao-e-samambaia-juridica-entenda-o-que-moraes-e-dino-quiseram-dizer-com-o-termo.ghtml\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "URL_ALVO = G1_HOME  # Ex.: 'https://g1.globo.com/politica/'\n",
        "LIMITE = 30         # 0 = sem limite\n",
        "\n",
        "try:\n",
        "    html = fetch_html(URL_ALVO)\n",
        "    headlines = parse_headlines(html, URL_ALVO)\n",
        "    if LIMITE and LIMITE > 0:\n",
        "        headlines = headlines[:LIMITE]\n",
        "    if not headlines:\n",
        "        print('Nenhuma manchete encontrada.')\n",
        "    else:\n",
        "        print(f'Total coletado: {len(headlines)}')\n",
        "        print('Manchetes principais (título + link):')\n",
        "        for i, (title, link) in enumerate(headlines, start=1):\n",
        "            print(f'{i:02d}. {title}')\n",
        "            print(f'    {link}')\n",
        "except Exception as e:\n",
        "    headlines = []\n",
        "    import traceback\n",
        "    print('Erro durante a coleta:', e)\n",
        "    traceback.print_exc()\n",
        "len(headlines) if 'headlines' in globals() else 0"
      ],
      "id": "run"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csv_title"
      },
      "source": [
        "## 6) Salvar resultados em CSV"
      ],
      "id": "csv_title"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1bedab0-2e33-4774-d669-260e96550a7e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Salvo em: g1_headlines.csv\n"
          ]
        }
      ],
      "source": [
        "CAMINHO_CSV = 'g1_headlines.csv'\n",
        "if 'headlines' in globals() and headlines:\n",
        "    save_to_csv(headlines, CAMINHO_CSV)\n",
        "    print(f'Salvo em: {CAMINHO_CSV}')\n",
        "else:\n",
        "    print('Nada para salvar: execute a coleta primeiro (célula 5).')"
      ],
      "id": "csv"
    }
  ]
}