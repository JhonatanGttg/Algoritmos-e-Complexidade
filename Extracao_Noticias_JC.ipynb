{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JhonatanGttg/Algoritmos-e-Complexidade/blob/main/Extracao_Noticias_JC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e31a4f8a",
      "metadata": {
        "id": "e31a4f8a"
      },
      "source": [
        "# Desafio: Extra√ß√£o de Not√≠cias com BeautifulSoup + Requests\n",
        "\n",
        "**Aluno:** Jhonatan Inacio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b7e0398d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7e0398d",
        "outputId": "c0cd5254-bfb6-4e8c-d76f-4bf6d8533f0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (5.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Instala√ß√£o das bibliotecas necess√°rias no Google Colab\n",
        "!pip install requests beautifulsoup4 pandas lxml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "431288f7",
      "metadata": {
        "id": "431288f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b352c715-d459-4ec2-973e-ec26b61c8d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Todas as bibliotecas foram importadas com sucesso!\n"
          ]
        }
      ],
      "source": [
        "# Importa√ß√£o das bibliotecas necess√°rias para web scraping\n",
        "import requests  # Para fazer requisi√ß√µes HTTP ao site\n",
        "from bs4 import BeautifulSoup  # Para analisar e extrair dados do HTML\n",
        "import pandas as pd  # Para manipula√ß√£o de dados e cria√ß√£o do CSV\n",
        "import re  # Para express√µes regulares (busca por padr√µes)\n",
        "from datetime import datetime  # Para trabalhar com datas\n",
        "import time  # Para adicionar delays se necess√°rio\n",
        "\n",
        "print(\"‚úÖ Todas as bibliotecas foram importadas com sucesso!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "239a4cda",
      "metadata": {
        "id": "239a4cda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c7cbba-0112-4a17-c8fd-cc7e8f3d5ea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåê Configura√ß√£o definida para acessar: https://jc.uol.com.br/\n",
            "ü§ñ User-Agent configurado para simular navegador\n"
          ]
        }
      ],
      "source": [
        "# Configura√ß√£o de headers HTTP para simular um navegador real\n",
        "# Isso ajuda a evitar que o site bloqueie nossa requisi√ß√£o\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
        "    'Accept-Language': 'pt-BR,pt;q=0.9,en;q=0.8',\n",
        "    'Connection': 'keep-alive'\n",
        "}\n",
        "\n",
        "# URL do site JC UOL conforme especificado na atividade\n",
        "url = \"https://jc.uol.com.br/\"\n",
        "\n",
        "print(f\"üåê Configura√ß√£o definida para acessar: {url}\")\n",
        "print(f\"ü§ñ User-Agent configurado para simular navegador\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "700d0410",
      "metadata": {
        "id": "700d0410"
      },
      "outputs": [],
      "source": [
        "def extrair_noticias_jc_uol():\n",
        "    \"\"\"\n",
        "    Fun√ß√£o principal para extrair not√≠cias do site JC UOL\n",
        "\n",
        "    Esta fun√ß√£o:\n",
        "    1. Faz uma requisi√ß√£o HTTP para o site\n",
        "    2. Analisa o HTML da p√°gina\n",
        "    3. Procura por elementos que cont√™m not√≠cias\n",
        "    4. Extrai t√≠tulo, link e data de cada not√≠cia\n",
        "    5. Retorna uma lista de dicion√°rios\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de dicion√°rios com t√≠tulo, link e data das not√≠cias\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Passo 1: Fazendo a requisi√ß√£o HTTP para a p√°gina inicial do JC UOL\n",
        "        print(\"üì° Fazendo requisi√ß√£o para o site JC UOL...\")\n",
        "        response = requests.get(url, headers=headers, timeout=15)\n",
        "\n",
        "        # Verificando se a requisi√ß√£o foi bem-sucedida (c√≥digo 200 = OK)\n",
        "        if response.status_code == 200:\n",
        "            print(f\"‚úÖ Requisi√ß√£o bem-sucedida! Status HTTP: {response.status_code}\")\n",
        "        else:\n",
        "            print(f\"‚ùå Erro na requisi√ß√£o. Status HTTP: {response.status_code}\")\n",
        "            return []\n",
        "\n",
        "        # Passo 2: Criando objeto BeautifulSoup para analisar o HTML\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        print(\"üîç Analisando estrutura HTML da p√°gina...\")\n",
        "\n",
        "        # Lista para armazenar todas as not√≠cias extra√≠das\n",
        "        noticias = []\n",
        "\n",
        "        # Passo 3: Estrat√©gia 1 - Buscar por tags <h2> (t√≠tulos principais)\n",
        "        print(\"üîé Estrat√©gia 1: Procurando manchetes em tags <h2>...\")\n",
        "        h2_elements = soup.find_all('h2')\n",
        "\n",
        "        for h2 in h2_elements:\n",
        "            # Procurando link dentro do h2 ou no elemento pai\n",
        "            link_element = h2.find('a') or h2.find_parent('a')\n",
        "\n",
        "            if link_element and h2.get_text(strip=True):\n",
        "                titulo = h2.get_text(strip=True)  # Extraindo texto limpo\n",
        "                link = link_element.get('href', '')  # Extraindo URL\n",
        "\n",
        "                # Convertendo links relativos em URLs completas\n",
        "                if link.startswith('/'):\n",
        "                    link = 'https://jc.uol.com.br' + link\n",
        "                elif not link.startswith('http'):\n",
        "                    link = 'https://jc.uol.com.br/' + link\n",
        "\n",
        "                # Usando data atual (pode ser melhorado para extrair data real)\n",
        "                data = datetime.now().strftime(\"%d/%m/%Y\")\n",
        "\n",
        "                # Filtro: s√≥ adiciona se t√≠tulo tem tamanho razo√°vel\n",
        "                if titulo and len(titulo) > 10:\n",
        "                    noticias.append({\n",
        "                        'titulo': titulo,\n",
        "                        'link': link,\n",
        "                        'data': data\n",
        "                    })\n",
        "\n",
        "        # Passo 4: Estrat√©gia 2 - Buscar por tags <h3> como backup\n",
        "        print(\"üîé Estrat√©gia 2: Procurando manchetes em tags <h3>...\")\n",
        "        h3_elements = soup.find_all('h3')\n",
        "\n",
        "        for h3 in h3_elements:\n",
        "            link_element = h3.find('a') or h3.find_parent('a')\n",
        "\n",
        "            if link_element and h3.get_text(strip=True):\n",
        "                titulo = h3.get_text(strip=True)\n",
        "                link = link_element.get('href', '')\n",
        "\n",
        "                # Convertendo links relativos\n",
        "                if link.startswith('/'):\n",
        "                    link = 'https://jc.uol.com.br' + link\n",
        "                elif not link.startswith('http'):\n",
        "                    link = 'https://jc.uol.com.br/' + link\n",
        "\n",
        "                data = datetime.now().strftime(\"%d/%m/%Y\")\n",
        "\n",
        "                # Evitando duplicatas: s√≥ adiciona se t√≠tulo ainda n√£o existe\n",
        "                if (titulo and len(titulo) > 10 and\n",
        "                    not any(n['titulo'] == titulo for n in noticias)):\n",
        "                    noticias.append({\n",
        "                        'titulo': titulo,\n",
        "                        'link': link,\n",
        "                        'data': data\n",
        "                    })\n",
        "\n",
        "        # Passo 5: Estrat√©gia 3 - Buscar links diretos com texto significativo\n",
        "        print(\"üîé Estrat√©gia 3: Procurando links diretos com t√≠tulos...\")\n",
        "        links = soup.find_all('a', href=True)\n",
        "\n",
        "        for link_elem in links:\n",
        "            titulo = link_elem.get_text(strip=True)\n",
        "            link = link_elem.get('href', '')\n",
        "\n",
        "            # Filtros para identificar links de not√≠cias v√°lidos\n",
        "            if (titulo and len(titulo) > 15 and  # T√≠tulo com tamanho m√≠nimo\n",
        "                ('jc.uol.com.br' in link or link.startswith('/')) and  # Link v√°lido\n",
        "                not any(palavra in titulo.lower() for palavra in ['publicidade', 'an√∫ncio', 'menu'])):\n",
        "\n",
        "                # Convertendo links relativos\n",
        "                if link.startswith('/'):\n",
        "                    link = 'https://jc.uol.com.br' + link\n",
        "                elif not link.startswith('http'):\n",
        "                    link = 'https://jc.uol.com.br/' + link\n",
        "\n",
        "                data = datetime.now().strftime(\"%d/%m/%Y\")\n",
        "\n",
        "                # Evitando duplicatas\n",
        "                if not any(n['titulo'] == titulo for n in noticias):\n",
        "                    noticias.append({\n",
        "                        'titulo': titulo,\n",
        "                        'link': link,\n",
        "                        'data': data\n",
        "                    })\n",
        "\n",
        "        # Limitando a 20 not√≠cias para n√£o sobrecarregar\n",
        "        noticias = noticias[:20]\n",
        "\n",
        "        print(f\"üì∞ Total de not√≠cias extra√≠das: {len(noticias)}\")\n",
        "        return noticias\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"‚ùå Erro na requisi√ß√£o HTTP: {e}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro inesperado durante extra√ß√£o: {e}\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "cce1e231",
      "metadata": {
        "id": "cce1e231"
      },
      "outputs": [],
      "source": [
        "def exibir_resultados(noticias):\n",
        "    \"\"\"\n",
        "    Exibe os resultados da extra√ß√£o de forma organizada no terminal\n",
        "\n",
        "    Esta fun√ß√£o formata e apresenta cada not√≠cia extra√≠da\n",
        "    mostrando t√≠tulo, link e data de forma leg√≠vel\n",
        "\n",
        "    Args:\n",
        "        noticias (list): Lista de dicion√°rios com as not√≠cias extra√≠das\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üìä RESULTADOS DA EXTRA√á√ÉO DE NOT√çCIAS DO JC UOL\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Verificando se h√° not√≠cias para exibir\n",
        "    if not noticias:\n",
        "        print(\"‚ùå Nenhuma not√≠cia foi extra√≠da. Verifique a conex√£o ou estrutura do site.\")\n",
        "        return\n",
        "\n",
        "    # Exibindo cada not√≠cia numerada\n",
        "    for i, noticia in enumerate(noticias, 1):\n",
        "        print(f\"\\nüì∞ Not√≠cia {i}:\")\n",
        "        print(f\"   üìù T√≠tulo: {noticia['titulo']}\")\n",
        "        print(f\"   üîó Link: {noticia['link']}\")\n",
        "        print(f\"   üìÖ Data: {noticia['data']}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "    print(f\"\\n‚úÖ Total de not√≠cias processadas: {len(noticias)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "b570abda",
      "metadata": {
        "id": "b570abda"
      },
      "outputs": [],
      "source": [
        "def salvar_csv(noticias, nome_arquivo=\"noticias_jc_uol.csv\"):\n",
        "    \"\"\"\n",
        "    Salva as not√≠cias extra√≠das em um arquivo CSV\n",
        "\n",
        "    Esta fun√ß√£o converte a lista de dicion√°rios em um DataFrame\n",
        "    do pandas e salva no formato CSV com encoding UTF-8\n",
        "\n",
        "    Args:\n",
        "        noticias (list): Lista de dicion√°rios com as not√≠cias\n",
        "        nome_arquivo (str): Nome do arquivo CSV a ser criado\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Verificando se h√° not√≠cias para salvar\n",
        "        if not noticias:\n",
        "            print(\"‚ùå N√£o h√° not√≠cias para salvar no CSV.\")\n",
        "            return\n",
        "\n",
        "        # Criando DataFrame do pandas a partir da lista de dicion√°rios\n",
        "        df = pd.DataFrame(noticias)\n",
        "\n",
        "        # Salvando em CSV com encoding UTF-8 (suporte a acentos)\n",
        "        df.to_csv(nome_arquivo, index=False, encoding='utf-8-sig')\n",
        "\n",
        "        print(f\"üíæ Arquivo CSV salvo com sucesso: {nome_arquivo}\")\n",
        "        print(f\"üìä Total de registros salvos: {len(noticias)}\")\n",
        "\n",
        "        # Mostrando preview dos primeiros registros\n",
        "        print(\"\\nüìã Preview dos dados salvos:\")\n",
        "        print(df.head().to_string(index=False, max_colwidth=50))\n",
        "\n",
        "        # Informa√ß√µes sobre o arquivo\n",
        "        print(f\"\\nüìÅ Estrutura do CSV:\")\n",
        "        print(f\"   - Colunas: {list(df.columns)}\")\n",
        "        print(f\"   - Linhas: {len(df)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao salvar arquivo CSV: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ba360ec8",
      "metadata": {
        "id": "ba360ec8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "599db4fb-eb49-463d-fe61-b76f65d02a81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ INICIANDO PROCESSO DE EXTRA√á√ÉO DE NOT√çCIAS DO JC UOL\n",
            "‚è±Ô∏è  Este processo pode levar alguns segundos...\n",
            "\n",
            "============================================================\n",
            "\n",
            "üîç ETAPA 1: Extraindo not√≠cias...\n",
            "üì° Fazendo requisi√ß√£o para o site JC UOL...\n",
            "‚úÖ Requisi√ß√£o bem-sucedida! Status HTTP: 200\n",
            "üîç Analisando estrutura HTML da p√°gina...\n",
            "üîé Estrat√©gia 1: Procurando manchetes em tags <h2>...\n",
            "üîé Estrat√©gia 2: Procurando manchetes em tags <h3>...\n",
            "üîé Estrat√©gia 3: Procurando links diretos com t√≠tulos...\n",
            "üì∞ Total de not√≠cias extra√≠das: 20\n",
            "\n",
            "üìä ETAPA 2: Exibindo resultados...\n",
            "\n",
            "================================================================================\n",
            "üìä RESULTADOS DA EXTRA√á√ÉO DE NOT√çCIAS DO JC UOL\n",
            "================================================================================\n",
            "\n",
            "üì∞ Not√≠cia 1:\n",
            "   üìù T√≠tulo: Ap√≥s campanha acirrada com 'Manas', Academia Brasileira de Cinema fez an√∫ncio: '√â um filme important√≠ssimo, que tem que ser dado o devido valor'\n",
            "   üîó Link: https://jc.uol.com.br/cultura/2025/09/15/o-agente-secreto-e-escolhido-para-disputar-categoria-de-melhor-filme-internacional-no-oscar.html\n",
            "   üìÖ Data: 15/09/2025\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üì∞ Not√≠cia 2:\n",
            "   üìù T√≠tulo: Cr√≠tica: 'O Agente Secreto' usa o thriller pol√≠tico para expor as lacunas da mem√≥ria no Brasil\n",
            "   üîó Link: https://jc.uol.com.br/cultura/2025/09/14/critica-o-agente-secreto-usa-o-thriller-politico-para-expor-as-lacunas-da-memoria-no-brasil.html\n",
            "   üìÖ Data: 15/09/2025\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üì∞ Not√≠cia 3:\n",
            "   üìù T√≠tulo: V√çDEOS DA TV JORNAL\n",
            "   üîó Link: https://jc.uol.com.br/tv-jornal/videos/\n",
            "   üìÖ Data: 15/09/2025\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üì∞ Not√≠cia 4:\n",
            "   üìù T√≠tulo: BLOG DO TORCEDOR\n",
            "   üîó Link: https://blogdotorcedor.com.br/\n",
            "   üìÖ Data: 15/09/2025\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üì∞ Not√≠cia 5:\n",
            "   üìù T√≠tulo: RECEITA DA BOA\n",
            "   üîó Link: https://receitadaboa.com.br/\n",
            "   üìÖ Data: 15/09/2025\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üì∞ Not√≠cia 6:\n",
            "   üìù T√≠tulo: Jornal do Commercio\n",
            "   üîó Link: https://jc.uol.com.br/\n",
            "   üìÖ Data: 15/09/2025\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üì∞ Not√≠cia 7:\n",
            "   üìù T√≠tulo: Sa√∫de e Bem-Estar\n",
            "   üîó Link: https://jc.uol.com.br/colunas/saude-e-bem-estar\n",
            "   üìÖ Data: 15/09/2025\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üì∞ Not√≠cia 8:\n",
            "   üìù T√≠tulo: Blog do Torcedor\n",
            "   üîó Link: https://jc.uol.com.br/blog-do-torcedor/\n",
            "   üìÖ Data: 15/09/2025\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üì∞ Not√≠cia 9:\n",
            "   üìù T√≠tulo: Recall de Marcas\n",
            "   üîó Link: https://jc.uol.com.br/recall-de-marcas\n",
            "   üìÖ Data: 15/09/2025\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üì∞ Not√≠cia 10:\n",
            "   üìù T√≠tulo: RELA√á√ÉOJulgamento de Bolsonaro acirra crise: Lula e Trump devem evitar encontro na ONU\n",
            "   üîó Link: https://jc.uol.com.br/politica/2025/09/15/julgamento-de-bolsonaro-acirra-crise-e-lula-e-trump-devem-evitar-encontro-na-onu.html\n",
            "   üìÖ Data: 15/09/2025\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üì∞ Not√≠cia 11:\n",
            "   üìù T√≠tulo: PoliticaTerezinha Nunes: A um ano da elei√ß√£o, pr√©-campanha ganha corpo no interior\n",
            "   üîó Link: https://jc.uol.com.br/colunas/blog-dellas/2025/09/15/com-um-ano-de-antecedencia-campanha-eleitoral-ganha-corpo-no-interior.html\n",
            "   üìÖ Data: 15/09/2025\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üì∞ Not√≠cia 12:\n",
            "   üìù T√≠tulo: OBESIDADEDoses mais potentes de Mounjaro chegam ao Brasil para tratamento da obesidade e diabetes tipo 2\n",
            "   üîó Link: https://jc.uol.com.br/colunas/saude-e-bem-estar/2025/09/15/doses-mais-potentes-de-mounjaro-chegam-ao-brasil-para-tratamento-da-obesidade-e-diabetes-tipo-2.html\n",
            "   üìÖ Data: 15/09/2025\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üì∞ Not√≠cia 13:\n",
            "   üìù T√≠tulo: Confer√™ncia do ClimaGrupo JCPM leva experi√™ncias para a COP30\n",
            "   üîó Link: https://jc.uol.com.br/economia/2025/09/15/grupo-jcpm-leva-experiencias-para-a-cop30.html\n",
            "   üìÖ Data: 15/09/2025\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üì∞ Not√≠cia 14:\n",
            "   üìù T√≠tulo: Tarifa Trump contra o Brasil\n",
            "   üîó Link: https://jc.uol.com.br/tag/tarifa/\n",
            "   üìÖ Data: 15/09/2025\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üì∞ Not√≠cia 15:\n",
            "   üìù T√≠tulo: Conflito Israel x Ir√£\n",
            "   üîó Link: https://jc.uol.com.br/tag/israel/\n",
            "   üìÖ Data: 15/09/2025\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üì∞ Not√≠cia 16:\n",
            "   üìù T√≠tulo: Raquel Lyra x Jo√£o Campos\n",
            "   üîó Link: https://jc.uol.com.br/estamos-de-olho/joao-e-raquel\n",
            "   üìÖ Data: 15/09/2025\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üì∞ Not√≠cia 17:\n",
            "   üìù T√≠tulo: Grupo JCPM 90 anos\n",
            "   üîó Link: https://jc.uol.com.br/tag/grupo-jcpm-90\n",
            "   üìÖ Data: 15/09/2025\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üì∞ Not√≠cia 18:\n",
            "   üìù T√≠tulo: EDUCA√á√ÉOGera√ß√£o Solid√°ria: projeto do Col√©gio N√∫cleo estimula protagonismo e coletividade dos estudantes\n",
            "   üîó Link: https://jc.uol.com.br/jc360/2025/09/12/geracao-solidaria-projeto-do-colegio-nucleo-estimula-protagonismo-e-coletividade-dos-estudantes.html\n",
            "   üìÖ Data: 15/09/2025\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üì∞ Not√≠cia 19:\n",
            "   üìù T√≠tulo: JC EDUCA√á√ÉOCol√©gio GGE: h√° 30 anos unindo cultura, tradi√ß√£o, inova√ß√£o e resultados\n",
            "   üîó Link: https://jc.uol.com.br/jc360/2025/09/12/colegio-gge-ha-30-anos-unindo-cultura-tradicao-inovacao-e-resultados.html\n",
            "   üìÖ Data: 15/09/2025\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üì∞ Not√≠cia 20:\n",
            "   üìù T√≠tulo: TECNOLOGIACol√©gio CBV lan√ßa disciplina inovadora voltada para IA\n",
            "   üîó Link: https://jc.uol.com.br/jc360/2025/09/12/colegio-cbv-lanca-disciplina-inovadora-voltada-para-ia.html\n",
            "   üìÖ Data: 15/09/2025\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚úÖ Total de not√≠cias processadas: 20\n",
            "\n",
            "üíæ ETAPA 3: Salvando em arquivo CSV...\n",
            "üíæ Arquivo CSV salvo com sucesso: noticias_jc_uol.csv\n",
            "üìä Total de registros salvos: 20\n",
            "\n",
            "üìã Preview dos dados salvos:\n",
            "                                            titulo                                               link       data\n",
            "Ap√≥s campanha acirrada com 'Manas', Academia Br... https://jc.uol.com.br/cultura/2025/09/15/o-agen... 15/09/2025\n",
            "Cr√≠tica: 'O Agente Secreto' usa o thriller pol√≠... https://jc.uol.com.br/cultura/2025/09/14/critic... 15/09/2025\n",
            "                               V√çDEOS DA TV JORNAL            https://jc.uol.com.br/tv-jornal/videos/ 15/09/2025\n",
            "                                  BLOG DO TORCEDOR                     https://blogdotorcedor.com.br/ 15/09/2025\n",
            "                                    RECEITA DA BOA                       https://receitadaboa.com.br/ 15/09/2025\n",
            "\n",
            "üìÅ Estrutura do CSV:\n",
            "   - Colunas: ['titulo', 'link', 'data']\n",
            "   - Linhas: 20\n",
            "\n",
            "============================================================\n",
            "‚úÖ PROCESSO CONCLU√çDO COM SUCESSO!\n",
            "üìÅ Verifique o arquivo 'noticias_jc_uol.csv' na pasta de downloads\n",
            "üéØ Atividade realizada conforme especifica√ß√µes da imagem\n"
          ]
        }
      ],
      "source": [
        "# üöÄ EXECU√á√ÉO PRINCIPAL DO PROGRAMA\n",
        "# Este √© o bloco principal que executa todo o processo de extra√ß√£o\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Fun√ß√£o principal que coordena todo o processo de extra√ß√£o de not√≠cias\n",
        "\n",
        "    Etapas:\n",
        "    1. Extrai not√≠cias do site JC UOL\n",
        "    2. Exibe resultados organizados\n",
        "    3. Salva dados em arquivo CSV\n",
        "    \"\"\"\n",
        "    print(\"üöÄ INICIANDO PROCESSO DE EXTRA√á√ÉO DE NOT√çCIAS DO JC UOL\")\n",
        "    print(\"‚è±Ô∏è  Este processo pode levar alguns segundos...\")\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "    # Etapa 1: Extraindo as not√≠cias do site\n",
        "    print(\"\\nüîç ETAPA 1: Extraindo not√≠cias...\")\n",
        "    noticias = extrair_noticias_jc_uol()\n",
        "\n",
        "    # Etapa 2: Exibindo resultados de forma organizada\n",
        "    print(\"\\nüìä ETAPA 2: Exibindo resultados...\")\n",
        "    exibir_resultados(noticias)\n",
        "\n",
        "    # Etapa 3: Salvando dados em CSV\n",
        "    print(\"\\nüíæ ETAPA 3: Salvando em arquivo CSV...\")\n",
        "    salvar_csv(noticias)\n",
        "\n",
        "    # Relat√≥rio final\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚úÖ PROCESSO CONCLU√çDO COM SUCESSO!\")\n",
        "    print(\"üìÅ Verifique o arquivo 'noticias_jc_uol.csv' na pasta de downloads\")\n",
        "    print(\"üéØ Atividade realizada conforme especifica√ß√µes da imagem\")\n",
        "\n",
        "    # Retornando dados para poss√≠vel an√°lise posterior\n",
        "    return noticias\n",
        "\n",
        "# Executando o programa principal\n",
        "noticias_extraidas = main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "1c13570c",
      "metadata": {
        "id": "1c13570c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08e2989b-5006-44fa-b333-4ecd97cc11fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç VERIFICA√á√ÉO FINAL DOS DADOS EXTRA√çDOS\n",
            "==================================================\n",
            "‚úÖ Total de not√≠cias coletadas: 20\n",
            "\n",
            "üìã Estrutura dos dados (conforme especificado na atividade):\n",
            "   - Formato: list (lista de dicion√°rios)\n",
            "   - Campos por not√≠cia: ['titulo', 'link', 'data']\n",
            "\n",
            "üìù Exemplo de uma not√≠cia extra√≠da:\n",
            "   {'titulo': \"Ap√≥s campanha acirrada com 'Manas', Academia Brasileira de Cinema fez an√∫ncio: '√â um filme important√≠ssimo, que tem que ser dado o devido valor'\", 'link': 'https://jc.uol.com.br/cultura/2025/09/15/o-agente-secreto-e-escolhido-para-disputar-categoria-de-melhor-filme-internacional-no-oscar.html', 'data': '15/09/2025'}\n"
          ]
        }
      ],
      "source": [
        "# üîç VERIFICA√á√ÉO FINAL DOS RESULTADOS\n",
        "# Este bloco permite verificar se tudo foi extra√≠do corretamente\n",
        "\n",
        "print(\"üîç VERIFICA√á√ÉO FINAL DOS DADOS EXTRA√çDOS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "if noticias_extraidas:\n",
        "    print(f\"‚úÖ Total de not√≠cias coletadas: {len(noticias_extraidas)}\")\n",
        "    print(\"\\nüìã Estrutura dos dados (conforme especificado na atividade):\")\n",
        "\n",
        "    # Mostrando exemplo da estrutura de dados\n",
        "    exemplo = noticias_extraidas[0] if noticias_extraidas else {}\n",
        "    print(f\"   - Formato: {type(noticias_extraidas).__name__} (lista de dicion√°rios)\")\n",
        "    print(f\"   - Campos por not√≠cia: {list(exemplo.keys()) if exemplo else 'N/A'}\")\n",
        "\n",
        "    # Exemplo de como os dados est√£o estruturados\n",
        "    if noticias_extraidas:\n",
        "        print(\"\\nüìù Exemplo de uma not√≠cia extra√≠da:\")\n",
        "        print(f\"   {noticias_extraidas[0]}\")\n",
        "    else:\n",
        "    print(\"‚ùå Nenhuma not√≠cia foi extra√≠da\")\n",
        "    print(\"üí° Poss√≠veis causas:\")\n",
        "    print(\"   - Problema de conex√£o com a internet\")\n",
        "    print(\"   - Site pode ter mudado sua estrutura\")\n",
        "    print(\"   - Bloqueio por parte do servidor\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}